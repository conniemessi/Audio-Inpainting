import torch
import torch.nn as nn
import torch.optim as optim
import torchaudio
import numpy as np
import matplotlib.pyplot as plt
from scipy.io import wavfile
import os

INPUT_FILE = "demo_assets/part2/damaged_gap.wav"
OUTPUT_DIR = "demo_assets/part2"


class GeneratorUNet(nn.Module):
    def __init__(self):
        super().__init__()
        self.enc1 = self.conv_block(1, 16)
        self.pool1 = nn.MaxPool2d(2)
        self.enc2 = self.conv_block(16, 32)
        self.pool2 = nn.MaxPool2d(2)
        self.bottleneck = self.conv_block(32, 64)
        self.up2 = nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2)
        self.dec2 = self.conv_block(64, 32)
        self.up1 = nn.ConvTranspose2d(32, 16, kernel_size=2, stride=2)
        self.dec1 = self.conv_block(32, 16)
        self.final = nn.Conv2d(16, 1, kernel_size=1)
    def conv_block(self, in_ch, out_ch):
        return nn.Sequential(
            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1),
            nn.BatchNorm2d(out_ch),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1),
            nn.BatchNorm2d(out_ch),
            nn.LeakyReLU(0.2, inplace=True)
        )
    def forward(self, x):
        e1 = self.enc1(x)
        p1 = self.pool1(e1)
        e2 = self.enc2(p1)
        p2 = self.pool2(e2)
        b = self.bottleneck(p2)
        d2 = self.up2(b)
        d2 = torch.nn.functional.interpolate(d2, size=e2.shape[2:]) 
        d2 = torch.cat((e2, d2), dim=1)
        d2 = self.dec2(d2)
        d1 = self.up1(d2)
        d1 = torch.nn.functional.interpolate(d1, size=e1.shape[2:])
        d1 = torch.cat((e1, d1), dim=1)
        d1 = self.dec1(d1)
        return torch.tanh(self.final(d1))

class Discriminator(nn.Module):
    def __init__(self):
        super().__init__()
        self.model = nn.Sequential(
            nn.Conv2d(1, 16, kernel_size=4, stride=2, padding=1),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(16, 32, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(32),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(64),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(64, 1, kernel_size=4, stride=1, padding=0),
            nn.Sigmoid()
        )
    def forward(self, x):
        return self.model(x)

class GANFairInpainter:
    def __init__(self):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # 1. åŠ è½½å—æŸæ–‡ä»¶
        if not os.path.exists(INPUT_FILE): raise FileNotFoundError("Missing damaged_gap.wav")
        waveform, sr = torchaudio.load(INPUT_FILE)
        if waveform.shape[0] > 1: waveform = torch.mean(waveform, dim=0, keepdim=True)
        self.sr = sr
        self.original_length = waveform.shape[1]
        
        # 2. é¢„å¤„ç†
        self.n_fft = 1024
        self.window = torch.hann_window(self.n_fft).to(self.device)
        waveform = waveform.to(self.device)
        stft = torch.stft(waveform, self.n_fft, hop_length=256, window=self.window, return_complex=True)
        
        self.magnitude = torch.abs(stft)
        self.phase = torch.angle(stft)
        
        # å½’ä¸€åŒ– (-1~1)
        self.mag_min = self.magnitude.min()
        self.mag_max = self.magnitude.max()
        self.magnitude_norm = (self.magnitude - self.mag_min) / (self.mag_max - self.mag_min)
        self.magnitude_norm = (self.magnitude_norm * 2) - 1
        
        # 3. åæ¨ Mask (é¢‘åŸŸèƒ½é‡æä½å¤„ä¸º 0)
        # è¿™é‡Œä¸ºäº†ç®€å•ï¼Œæˆ‘ä»¬å‡è®¾ä¸­é—´çš„ä¸€å¤§å—é™éŸ³å°±æ˜¯ Gap
        self.mask = (self.magnitude_norm > -0.95).float() # é˜ˆå€¼ç¨å¾®å®½ä¸€ç‚¹ï¼Œå› ä¸ºé™éŸ³åŒºå½’ä¸€åŒ–åæ˜¯ -1
        
        # å‡†å¤‡ Tensor
        self.input_mag = self.magnitude_norm # å·²ç»æ˜¯å—æŸçš„äº†
        self.real_mag = self.magnitude_norm  # åœ¨ GAN è®­ç»ƒä¸­ï¼ŒTarget å…¶å®åº”è¯¥æ˜¯ Original
        # ä½†è¿™é‡Œæ˜¯ Inpaintingï¼Œæˆ‘ä»¬åªèƒ½åŸºäº Context è®­ç»ƒï¼Œæˆ–è€…åŠ è½½ Original.wav ä½œä¸º Target
        # ä¸ºäº†å…¬å¹³è®­ç»ƒï¼Œæœ€å¥½åŠ è½½ Original.wavï¼Œä½†å¦‚æœæ˜¯çº¯ Inferenceï¼Œåˆ™ä¸éœ€è¦ã€‚
        # å‡è®¾æˆ‘ä»¬ç°åœ¨æ˜¯åœ¨åšâ€œä¿®å¤æ¼”ç¤ºâ€ï¼Œæˆ‘ä»¬ç›´æ¥åŠ è½½æ¨¡å‹æƒé‡è¿›è¡Œä¿®å¤ã€‚
        # å¦‚æœè¦ç°åœºè®­ç»ƒï¼Œæˆ‘ä»¬éœ€è¦ Original.wavã€‚ä¸ºäº†å…¬å¹³ï¼Œæˆ‘ä»¬åŠ ä¸Šå®ƒã€‚
        
        orig_wav, _ = torchaudio.load("demo_assets/original.wav")
        if orig_wav.shape[0]>1: orig_wav = torch.mean(orig_wav, dim=0, keepdim=True)
        orig_wav = orig_wav[:, :self.original_length].to(self.device)
        stft_orig = torch.stft(orig_wav, self.n_fft, hop_length=256, window=self.window, return_complex=True)
        self.real_mag = (torch.abs(stft_orig) - self.mag_min) / (self.mag_max - self.mag_min)
        self.real_mag = (self.real_mag * 2) - 1
        
        self.input_tensor = self.input_mag.unsqueeze(0)
        self.real_tensor = self.real_mag.unsqueeze(0)
        self.mask_tensor = self.mask.unsqueeze(0)

        self.netG = GeneratorUNet().to(self.device)
        self.netD = Discriminator().to(self.device)

    def train(self, epochs=1000):
        # ... (è®­ç»ƒä»£ç åŒä¹‹å‰ï¼Œçœç•¥ä»¥èŠ‚çœç©ºé—´ï¼Œé€»è¾‘ä¸€è‡´) ...
        # ç®€ç•¥ç‰ˆè®­ç»ƒå¾ªç¯
        optimizerG = optim.Adam(self.netG.parameters(), lr=0.0002, betas=(0.5, 0.999))
        optimizerD = optim.Adam(self.netD.parameters(), lr=0.0002, betas=(0.5, 0.999))
        criterionGAN = nn.BCELoss()
        criterionL1 = nn.L1Loss()
        
        print(f"âš”ï¸ GAN æ­£åœ¨ä¿®å¤å—æŸæ–‡ä»¶ ({epochs} epochs)...")
        for epoch in range(epochs):
            # è®­ç»ƒ D
            self.netD.zero_grad()
            out_real = self.netD(self.real_tensor)
            loss_d_real = criterionGAN(out_real, torch.ones_like(out_real))
            
            fake = self.netG(self.input_tensor)
            completed = self.input_tensor * self.mask_tensor + fake * (1 - self.mask_tensor)
            out_fake = self.netD(completed.detach())
            loss_d_fake = criterionGAN(out_fake, torch.zeros_like(out_fake))
            loss_d = (loss_d_real + loss_d_fake) * 0.5
            loss_d.backward()
            optimizerD.step()
            
            # è®­ç»ƒ G
            self.netG.zero_grad()
            out_fake_g = self.netD(completed)
            loss_g_adv = criterionGAN(out_fake_g, torch.ones_like(out_fake_g))
            loss_g_rec = criterionL1(fake * (1-self.mask_tensor), self.real_tensor * (1-self.mask_tensor))
            loss_g = loss_g_rec * 0.99 + loss_g_adv * 0.01
            loss_g.backward()
            optimizerG.step()
            
            if (epoch+1)%200==0: print(f"Epoch {epoch+1}: Loss D={loss_d.item():.4f}, Loss G={loss_g.item():.4f}")

        # ç”Ÿæˆæœ€ç»ˆç»“æœ
        self.netG.eval()
        with torch.no_grad():
            fake = self.netG(self.input_tensor)
            final = self.input_tensor * self.mask_tensor + fake * (1 - self.mask_tensor)
            final = (final + 1) / 2
            final = final * (self.mag_max - self.mag_min) + self.mag_min
            
            stft_recon = torch.polar(final.squeeze(0), self.phase) # ç”¨åŸå§‹ç›¸ä½(è™½ç„¶Gapå¤„ä¸å‡†)
            self.restored_waveform = torch.istft(stft_recon, self.n_fft, hop_length=256, window=self.window, length=self.original_length)

    def save_result(self):
        path = os.path.join(OUTPUT_DIR, "fixed_gan_gap.wav")
        sig = self.restored_waveform.squeeze().cpu().numpy()
        sig = np.clip(sig, -1.0, 1.0)
        wavfile.write(path, self.sr, (sig * 32767).astype(np.int16))
        
        plt.figure(figsize=(10, 4))
        plt.specgram(sig, NFFT=1024, Fs=self.sr, noverlap=512, cmap='inferno')
        plt.axis('off')
        plt.tight_layout(pad=0)
        plt.savefig(os.path.join(OUTPUT_DIR, "spec_gan_gap.png"), bbox_inches='tight', pad_inches=0)
        print("ğŸ’¾ GAN ä¿®å¤å®Œæ¯• (fixed_gan_gap.wav + png)")

# è¿è¡Œ
lab = GANFairInpainter()
lab.train(epochs=1500)
lab.save_result()