import torch
import torch.nn as nn
import torch.optim as optim
import torchaudio
import numpy as np
import matplotlib.pyplot as plt
from scipy.io import wavfile
import os

# --- 1. å®šä¹‰ U-Net ç½‘ç»œæ¶æ„ ---
class SimpleUNet(nn.Module):
    def __init__(self):
        super().__init__()
        # ç¼–ç å™¨ (Encoder): ä¸‹é‡‡æ ·ï¼Œæå–ç‰¹å¾
        self.enc1 = self.conv_block(1, 16)
        self.pool1 = nn.MaxPool2d(2)
        self.enc2 = self.conv_block(16, 32)
        self.pool2 = nn.MaxPool2d(2)
        self.bottleneck = self.conv_block(32, 64)

        # è§£ç å™¨ (Decoder): ä¸Šé‡‡æ ·ï¼Œæ¢å¤å›¾åƒ
        self.up2 = nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2)
        self.dec2 = self.conv_block(64, 32) # è¾“å…¥æ˜¯ 64 å› ä¸ºæ‹¼æ¥äº† skip connection
        self.up1 = nn.ConvTranspose2d(32, 16, kernel_size=2, stride=2)
        self.dec1 = self.conv_block(32, 16)
        
        # è¾“å‡ºå±‚
        self.final = nn.Conv2d(16, 1, kernel_size=1)

    def conv_block(self, in_ch, out_ch):
        return nn.Sequential(
            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1),
            nn.ReLU(inplace=True)
        )

    def forward(self, x):
        # ç¼–ç è·¯å¾„
        e1 = self.enc1(x)
        p1 = self.pool1(e1)
        e2 = self.enc2(p1)
        p2 = self.pool2(e2)
        
        # ç“¶é¢ˆå±‚
        b = self.bottleneck(p2)
        
        # è§£ç è·¯å¾„ (å¸¦è·³è·ƒè¿æ¥ Skip Connections)
        d2 = self.up2(b)
        # è°ƒæ•´å°ºå¯¸ä»¥é˜² padding å¯¼è‡´çš„ä¸åŒ¹é…
        d2 = torch.nn.functional.interpolate(d2, size=e2.shape[2:]) 
        d2 = torch.cat((e2, d2), dim=1) # æ‹¼æ¥!
        d2 = self.dec2(d2)
        
        d1 = self.up1(d2)
        d1 = torch.nn.functional.interpolate(d1, size=e1.shape[2:])
        d1 = torch.cat((e1, d1), dim=1) # æ‹¼æ¥!
        d1 = self.dec1(d1)
        
        return self.final(d1)

# --- 2. æ•°æ®å¤„ç†ä¸è®­ç»ƒæµç¨‹ ---
class DLInpaintingLab:
    def __init__(self, filename, duration=0.3):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ğŸš€ Using device: {self.device}")
        
        # åŠ è½½éŸ³é¢‘
        waveform, sr = torchaudio.load(filename)
        
        # 1. å¼ºåˆ¶è½¬å•å£°é“
        if waveform.shape[0] > 1:
            waveform = torch.mean(waveform, dim=0, keepdim=True)
            
        waveform = waveform[:, :int(duration*sr)] # æˆªå–
        self.sr = sr
        
        # --- ğŸ› ï¸ ä¿®å¤ç‚¹ A: ä¿å­˜åŸå§‹é•¿åº¦ ---
        self.original_length = waveform.shape[1]
        
        # 2. åˆ›å»ºå¹¶ä¿å­˜ Window (è§£å†³è­¦å‘Š + ä¿è¯é€†å˜æ¢å‡†ç¡®)
        self.n_fft = 1024
        self.window = torch.hann_window(self.n_fft).to(self.device)
        
        # STFT
        waveform = waveform.to(self.device)
        stft = torch.stft(waveform, self.n_fft, hop_length=256, 
                          window=self.window, return_complex=True)
        
        self.magnitude = torch.abs(stft)
        self.phase = torch.angle(stft)
        
        # å½’ä¸€åŒ–
        self.mag_max = self.magnitude.max()
        self.magnitude_norm = self.magnitude / self.mag_max
        
        # Mask
        _, freq, time = self.magnitude.shape
        gap_start = int(time * 0.4)
        gap_end = int(time * 0.6)
        self.mask = torch.ones_like(self.magnitude_norm)
        self.mask[:, :, gap_start:gap_end] = 0
        
        # Tensors
        self.input_mag = self.magnitude_norm * self.mask
        self.target_mag = self.magnitude_norm
        
        self.input_tensor = self.input_mag.unsqueeze(0)
        self.target_tensor = self.target_mag.unsqueeze(0)
        self.mask_tensor = self.mask.unsqueeze(0)

        self.model = SimpleUNet().to(self.device)
        self.restored_waveform = None
        self.corrupted_waveform = None
        
        # é¢„å…ˆåˆ›å»ºæŸåçš„éŸ³é¢‘æ³¢å½¢ç”¨äºå¯¹æ¯”
        self._create_corrupted_waveform()

    def _create_corrupted_waveform(self):
        """ä»æŸåçš„è¾“å…¥è°±å›¾é‡å»ºéŸ³é¢‘æ³¢å½¢"""
        # ä½¿ç”¨æŸåçš„å¹…åº¦è°±å’ŒåŸå§‹ç›¸ä½é‡å»º
        corrupted_mag = self.input_mag * self.mag_max
        stft_corrupted = torch.polar(corrupted_mag, self.phase)
        
        self.corrupted_waveform = torch.istft(
            stft_corrupted,
            self.n_fft,
            hop_length=256,
            window=self.window,
            length=self.original_length
        )

    def train_and_predict(self, epochs=600):
        optimizer = optim.Adam(self.model.parameters(), lr=0.001)
        criterion = nn.MSELoss()
        
        print(f"ğŸ§  å¼€å§‹è®­ç»ƒ U-Net (è¿‡æ‹Ÿåˆæ¼”ç¤ºï¼Œå…± {epochs} è½®)...")
        for epoch in range(epochs):
            self.model.train()
            optimizer.zero_grad()
            output = self.model(self.input_tensor)
            loss = criterion(output, self.target_tensor)
            loss.backward()
            optimizer.step()
            
            if (epoch+1) % 100 == 0:
                print(f"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.6f}")
                
        # æ¨ç†
        self.model.eval()
        with torch.no_grad():
            predicted_mag_norm = self.model(self.input_tensor)
            
        final_mag_norm = self.input_mag.to(self.device) + predicted_mag_norm * (1 - self.mask_tensor)
        final_mag = final_mag_norm.squeeze(0) * self.mag_max
        
        # iSTFT é‡å»º
        stft_reconstructed = torch.polar(final_mag, self.phase)
        
        # --- ğŸš¨ å…³é”®ä¿®æ”¹çœ‹è¿™é‡Œ ğŸš¨ ---
        # è¿™ä¸€è¡Œå¿…é¡»æ”¹ï¼ä¸èƒ½ç”¨ waveform.shape[1]ï¼Œè¦ç”¨ self.original_length
        self.restored_waveform = torch.istft(
            stft_reconstructed, 
            self.n_fft, 
            hop_length=256, 
            window=self.window, 
            length=self.original_length  # <--- è¿™é‡Œæ”¹æˆäº† self.original_length
        )

    def visualize(self):
        plt.figure(figsize=(15, 5))
        
        plt.subplot(1, 3, 1)
        plt.title("Input (Corrupted)")
        plt.imshow(self.input_mag.squeeze().cpu().numpy(), aspect='auto', origin='lower', cmap='inferno')
        plt.axis('off')

        self.model.eval()
        with torch.no_grad():
            pred = self.model(self.input_tensor).squeeze(0).squeeze(0).cpu()
        
        plt.subplot(1, 3, 2)
        plt.title("U-Net Prediction")
        plt.imshow(pred.numpy(), aspect='auto', origin='lower', cmap='inferno')
        plt.axis('off')
        
        plt.subplot(1, 3, 3)
        plt.title("Ground Truth")
        plt.imshow(self.target_mag.squeeze().cpu().numpy(), aspect='auto', origin='lower', cmap='inferno')
        plt.axis('off')
        
        plt.tight_layout()
        plt.show()

    def save_wav(self):
        # ä¿å­˜æŸåçš„éŸ³é¢‘ï¼ˆä¿®å¤å‰ï¼‰
        if self.corrupted_waveform is not None:
            sig_corrupted = self.corrupted_waveform.squeeze().cpu().numpy()
            sig_corrupted = np.clip(sig_corrupted, -0.99, 0.99)
            wavfile.write("dl_corrupted.wav", self.sr, (sig_corrupted * 32767).astype(np.int16))
            print("ğŸ’¾ æŸåçš„éŸ³é¢‘å·²ä¿å­˜: dl_corrupted.wav")
        
        # ä¿å­˜ä¿®å¤åçš„éŸ³é¢‘
        sig = self.restored_waveform.squeeze().cpu().numpy()
        sig = np.clip(sig, -0.99, 0.99)
        wavfile.write("dl_restored.wav", self.sr, (sig * 32767).astype(np.int16))
        print("ğŸ’¾ æ·±åº¦å­¦ä¹ ä¿®å¤åçš„éŸ³é¢‘å·²ä¿å­˜: dl_restored.wav")

# --- ğŸƒâ€â™‚ï¸ è¿è¡Œ ---
# âš ï¸ æ³¨æ„ï¼šå¦‚æœä½ æ²¡æœ‰ GPUï¼Œè¿™å¯èƒ½éœ€è¦è·‘ä¸€ä¸¤åˆ†é’Ÿã€‚
lab = DLInpaintingLab(filename="vocals_accompaniment_10s.wav", duration=10)
lab.train_and_predict(epochs=600) # è®­ç»ƒ 600 è½®ç¡®ä¿è¿‡æ‹Ÿåˆ
lab.visualize()
lab.save_wav()