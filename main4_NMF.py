import numpy as np
import matplotlib.pyplot as plt
from scipy.io import wavfile
from scipy import signal
from sklearn.decomposition import NMF
import os

# Unified configuration
OUTPUT_DIR = "demo_assets/part0"
os.makedirs(OUTPUT_DIR, exist_ok=True)

def save_spectrogram(audio, sr, save_name):
    """Save spectrogram with consistent style"""
    plt.figure(figsize=(10, 4))
    plt.specgram(audio, NFFT=1024, Fs=sr, noverlap=512, cmap='inferno')
    plt.axis('off')
    plt.tight_layout(pad=0)
    plt.savefig(os.path.join(OUTPUT_DIR, save_name), bbox_inches='tight', pad_inches=0)
    plt.close()
    print(f"ğŸ–¼ï¸  Spectrogram saved: {save_name}")

def save_wav(audio, sr, save_name):
    """Save audio file"""
    audio = np.clip(audio, -1.0, 1.0)
    wavfile.write(os.path.join(OUTPUT_DIR, save_name), sr, (audio * 32767).astype(np.int16))
    print(f"ğŸ’¾ Audio saved: {save_name}")

class SpectralInpainter:
    def __init__(self, filename, duration=0.1): # ç¨å¾®é•¿ä¸€ç‚¹ï¼Œæ–¹ä¾¿çœ‹è°±å›¾
        self.filename = filename
        self.duration = duration
        self.sr = None
        self.raw_audio = None
        self.restored_audio = None
        
    def load_data(self):
        self.sr, data = wavfile.read(self.filename)
        if data.dtype != np.float32:
            data = data.astype(np.float32) / np.iinfo(data.dtype).max if data.dtype != np.float32 else data
        if len(data.shape) > 1: data = data.mean(axis=1)
        # Normalize
        data = data / np.max(np.abs(data)) if np.max(np.abs(data)) > 0 else data
        
        # Extract segment
        n = int(self.duration * self.sr)
        start = len(data) // 2
        self.raw_audio = data[start : start + n]
        print(f"ğŸŒŠ Audio loaded: {len(self.raw_audio)} samples")

    def apply_mask(self, gap_ratio=0.2):
        n = len(self.raw_audio)
        self.gap_start = int(n * 0.4)
        self.gap_end = int(self.gap_start + n * gap_ratio)
        
        self.corrupted_audio = self.raw_audio.copy()
        # Smooth edges in time domain to avoid STFT Gibbs effect
        fade_len = min(100, self.gap_start, n - self.gap_end)
        if fade_len > 0:
            window = np.linspace(1, 0, fade_len)
            self.corrupted_audio[self.gap_start-fade_len:self.gap_start] *= window
            self.corrupted_audio[self.gap_end:self.gap_end+fade_len] *= window[::-1]
        self.corrupted_audio[self.gap_start:self.gap_end] = 0
        
        return self.gap_start, self.gap_end

    def restore_with_nmf(self, n_components=30, n_iter=20):
        """
        æ ¸å¿ƒç®—æ³•ï¼š
        1. STFT è½¬æ¢åˆ°é¢‘åŸŸ
        2. ä½¿ç”¨ NMF å­¦ä¹ é¢‘è°±ç‰¹å¾ (W) å’Œ æ—¶é—´æ¿€æ´» (H)
        3. è¿­ä»£å¡«å……ç¼ºå£
        """
        # 1. STFT (çŸ­æ—¶å‚…é‡Œå¶å˜æ¢)
        # nperseg å†³å®šäº†é¢‘ç‡åˆ†è¾¨ç‡ï¼Œé‡å éƒ¨åˆ†å†³å®šäº†æ—¶é—´åˆ†è¾¨ç‡
        f, t, Zxx = signal.stft(self.corrupted_audio, self.sr, nperseg=512, noverlap=384)
        
        # åˆ†ç¦» å¹…åº¦(Magnitude) å’Œ ç›¸ä½(Phase)
        magnitude = np.abs(Zxx)
        phase = np.angle(Zxx)
        
        # ç¡®å®šç¼ºå£åœ¨ Spectrogram ä¸Šçš„æ—¶é—´åˆ—ç´¢å¼•
        t_step = t[1] - t[0]
        col_start = int(self.gap_start / self.sr / t_step)
        col_end = int(self.gap_end / self.sr / t_step)
        
        # 2. è¿­ä»£ä¿®å¤ (Iterative NMF Inpainting)
        # åˆå§‹åŒ–ï¼šç”¨éšæœºå™ªå£°æˆ–å¹³å‡å€¼å¡«å……ç¼ºå£ï¼Œç»™ NMF ä¸€ä¸ªèµ·ç‚¹
        current_mag = magnitude.copy()
        avg_spectrum = np.mean(magnitude[:, :col_start], axis=1, keepdims=True)
        current_mag[:, col_start:col_end] = avg_spectrum 
        
        model = NMF(n_components=n_components, init='random', random_state=0, max_iter=200)

        print(f"ğŸ¨ æ­£åœ¨è¿›è¡Œè°±å›¾é‡ç»˜ (Iterating {n_iter} times)...")
        for i in range(n_iter):
            # åˆ†è§£ V â‰ˆ W * H
            W = model.fit_transform(current_mag) # å­¦ä¹ åŸºå‘é‡ W
            H = model.components_              # å­¦ä¹ æ¿€æ´»ç³»æ•° H
            
            # é‡å»º V_hat
            V_hat = W @ H
            
            # å…³é”®æ­¥éª¤ï¼šåªæ›´æ–°ç¼ºå£éƒ¨åˆ†ï¼ä¿ç•™å·²çŸ¥éƒ¨åˆ†ï¼
            current_mag[:, col_start:col_end] = V_hat[:, col_start:col_end]
        
        # 3. iSTFT (é€†å˜æ¢) å›åˆ°æ—¶åŸŸ
        # æˆ‘ä»¬ä½¿ç”¨åŸå§‹çš„ç›¸ä½ (Phase)ï¼Œè™½ç„¶ç¼ºå£å¤„ç›¸ä½æ˜¯ä¹±çš„ï¼Œä½† Griffin-Lim ç®—æ³•é€šå¸¸ç”¨æ¥ä¼°è®¡ç›¸ä½
        # è¿™é‡Œä¸ºäº†ç®€åŒ–ï¼Œæˆ‘ä»¬æ··åˆä½¿ç”¨ï¼šä¿ç•™åŸå§‹ç›¸ä½ï¼Œç¼ºå£å¤„ä½¿ç”¨é‡å»ºå¹…åº¦çš„ç›¸ä½(å‡è®¾ä¸º0æˆ–è€…æ²¿ç”¨)
        # æ›´é«˜çº§çš„åšæ³•æ˜¯ Griffin-Limï¼Œè¿™é‡Œæˆ‘ä»¬ç®€å•åœ°å°† Magnitude å’Œ åŸå§‹ Phase ç»“åˆ
        # æ³¨æ„ï¼šç¼ºå£å¤„çš„ Phase ä¸¢å¤±äº†ï¼Œæˆ‘ä»¬æš‚æ—¶ç”¨ 0 æˆ–è€…ä¸´è¿‘çš„ä»£æ›¿ï¼Œæˆ–è€…ç›´æ¥ä¿¡èµ– Magnitude
        
        Zxx_restored = current_mag * np.exp(1j * phase)
        _, self.restored_audio = signal.istft(Zxx_restored, self.sr, nperseg=512, noverlap=384)
        
        # æˆªæ–­åˆ°åŸå§‹é•¿åº¦
        self.restored_audio = self.restored_audio[:len(self.raw_audio)]
        
        # ç®€å•çš„æ·¡å…¥æ·¡å‡ºèåˆï¼Œæ¶ˆé™¤çˆ†éŸ³
        self._blend_boundaries()
        
        return self.restored_audio

    def _blend_boundaries(self):
        # å°†ä¿®å¤åçš„ç‰‡æ®µå®Œç¾è´´å›åŸå§‹éŸ³é¢‘
        final = self.raw_audio.copy()
        gs, ge = self.gap_start, self.gap_end
        
        # åœ¨æ¥ç¼å¤„åšå¾®å°çš„ Cross-fade
        blend_width = 50
        mask = np.linspace(0, 1, blend_width)
        
        # å¡«å……ä¸­é—´
        final[gs:ge] = self.restored_audio[gs:ge]
        
        # å¤„ç†å·¦æ¥ç¼
        final[gs-blend_width:gs] = final[gs-blend_width:gs] * (1-mask) + self.restored_audio[gs-blend_width:gs] * mask
        # å¤„ç†å³æ¥ç¼
        final[ge:ge+blend_width] = final[ge:ge+blend_width] * mask + self.restored_audio[ge:ge+blend_width] * (1-mask)
        
        self.restored_audio = final

    def save_results(self):
        """Save audio files and spectrograms"""
        save_wav(self.corrupted_audio, self.sr, "nmf_corrupted.wav")
        save_spectrogram(self.corrupted_audio, self.sr, "spec_nmf_corrupted.png")
        
        save_wav(self.restored_audio, self.sr, "nmf_restored.wav")
        save_spectrogram(self.restored_audio, self.sr, "spec_nmf_restored.png")
        
        save_wav(self.raw_audio, self.sr, "nmf_original.wav")
        save_spectrogram(self.raw_audio, self.sr, "spec_nmf_original.png")

    def visualize(self):
        plt.figure(figsize=(14, 8))
        
        # ç”»æ—¶åŸŸæ³¢å½¢
        plt.subplot(2, 1, 1)
        plt.plot(self.raw_audio, 'gray', alpha=0.5, label="Original")
        plt.plot(self.restored_audio, 'b--', alpha=0.8, linewidth=1, label="NMF Restored")
        plt.axvspan(self.gap_start, self.gap_end, color='red', alpha=0.1, label="Gap")
        plt.legend()
        plt.title("Time Domain: Waveform")
        
        # ç”»é¢‘åŸŸè°±å›¾ (Spectrogram)
        plt.subplot(2, 1, 2)
        f, t, Zxx = signal.stft(self.restored_audio, self.sr, nperseg=512)
        plt.pcolormesh(t, f, np.abs(Zxx), shading='gouraud', cmap='inferno')
        plt.axvline(self.gap_start/self.sr, color='white', linestyle='--')
        plt.axvline(self.gap_end/self.sr, color='white', linestyle='--')
        plt.title("Frequency Domain: Restored Spectrogram")
        plt.ylabel("Frequency [Hz]")
        plt.xlabel("Time [sec]")
        
        plt.tight_layout()
        plt.savefig(os.path.join(OUTPUT_DIR, "nmf_waveform_viz.png"), dpi=300, bbox_inches='tight')
        print(f"ğŸ“Š Waveform visualization saved")
        plt.show()

# --- ğŸƒâ€â™‚ï¸ Run ---
if __name__ == "__main__":
    # Unified parameters
    DURATION = 0.05
    GAP_RATIO = 0.2
    
    lab = SpectralInpainter(filename="vocals_accompaniment_10s.wav", duration=DURATION)
    lab.load_data()
    lab.apply_mask(gap_ratio=GAP_RATIO)
    lab.restore_with_nmf(n_components=40, n_iter=50)
    lab.save_results()
    lab.visualize()
    
    print(f"âœ… NMF restoration complete! Results in {OUTPUT_DIR}")