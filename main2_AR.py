import numpy as np
import matplotlib.pyplot as plt
from scipy.io import wavfile
from sklearn.linear_model import Ridge
import os

# Unified configuration
OUTPUT_DIR = "demo_assets/part0"
os.makedirs(OUTPUT_DIR, exist_ok=True)

def save_spectrogram(audio, sr, save_name):
    """Save spectrogram with consistent style"""
    plt.figure(figsize=(10, 4))
    plt.specgram(audio, NFFT=1024, Fs=sr, noverlap=512, cmap='inferno')
    plt.axis('off')
    plt.tight_layout(pad=0)
    plt.savefig(os.path.join(OUTPUT_DIR, save_name), bbox_inches='tight', pad_inches=0)
    plt.close()
    print(f"ğŸ–¼ï¸  Spectrogram saved: {save_name}")

def save_wav(audio, sr, save_name):
    """Save audio file"""
    audio = np.clip(audio, -1.0, 1.0)
    wavfile.write(os.path.join(OUTPUT_DIR, save_name), sr, (audio * 32767).astype(np.int16))
    print(f"ğŸ’¾ Audio saved: {save_name}")

class BidirectionalARInpainter:
    def __init__(self, filename, duration=0.05, order=20):
        """
        order: ARæ¨¡å‹çš„é˜¶æ•°ã€‚æ„æ€æ˜¯â€œæˆ‘çœ‹è¿‡å»çš„ 20 ä¸ªç‚¹æ¥é¢„æµ‹ä¸‹ 1 ä¸ªç‚¹â€
        """
        self.filename = filename
        self.duration = duration
        self.order = order # è¿™é‡Œçš„ order å¾ˆå…³é”®ï¼Œäººå£°é€šå¸¸ 10-30 æ¯”è¾ƒåˆé€‚
        self.sr = None
        self.signal = None
        self.t = None
        self.mask = None

    def load_data(self):
        self.sr, data = wavfile.read(self.filename)
        # è½¬å•å£°é“ & å½’ä¸€åŒ–
        if len(data.shape) > 1: data = data.mean(axis=1)
        data = data / np.max(np.abs(data))
        
        # æˆªå–ä¸€æ®µ
        n = int(self.duration * self.sr)
        start = len(data) // 2
        self.signal = data[start : start + n]
        self.t = np.arange(n) / self.sr
        print(f"ğŸ¤ å·²åŠ è½½éŸ³é¢‘ï¼ŒAR é˜¶æ•°: {self.order}")

    def apply_mask(self, gap_ratio=0.15):
        n = len(self.signal)
        gap_len = int(n * gap_ratio)
        start = int(n * 0.4)
        self.mask = np.ones(n, dtype=bool)
        self.mask[start : start+gap_len] = False
        self.gap_range = (start, start+gap_len)
        return self.gap_range

    def _train_predict(self, context_X, context_y, steps, reverse=False):
        """
        æ ¸å¿ƒå¼•æ“ï¼šè®­ç»ƒä¸€ä¸ªå°çš„çº¿æ€§å›å½’æ¨¡å‹æ¥æ¨¡ä»¿æ³¢å½¢çš„èµ°åŠ¿
        """
        model = Ridge(alpha=0.1) # ä½¿ç”¨ Ridge é˜²æ­¢è¿‡æ‹Ÿåˆ
        model.fit(context_X, context_y)
        
        # é€æ­¥é¢„æµ‹ (Autoregressive step-by-step)
        # æˆ‘ä»¬ä¸ä»…é¢„æµ‹ä¸€æ­¥ï¼Œè€Œæ˜¯æŠŠé¢„æµ‹ç»“æœä½œä¸ºè¾“å…¥ï¼Œé¢„æµ‹ä¸‹ä¸€æ­¥ï¼Œä»¥æ­¤ç±»æ¨
        current_input = context_X[-1].copy() # æ‹¿åˆ°æœ€è¿‘çš„ä¸€ç»„è¾“å…¥
        predictions = []
        
        for _ in range(steps):
            pred = model.predict(current_input.reshape(1, -1))[0]
            predictions.append(pred)
            
            # æ›´æ–°è¾“å…¥çª—å£ï¼šæ‰”æ‰æœ€æ—§çš„ï¼ŒåŠ å…¥æœ€æ–°çš„é¢„æµ‹å€¼
            current_input = np.roll(current_input, -1)
            current_input[-1] = pred
            
        return np.array(predictions)

    def restore(self):
        gap_start, gap_end = self.gap_range
        gap_len = gap_end - gap_start
        
        # --- 1. å‡†å¤‡è®­ç»ƒæ•°æ® (æ„å»º AR çŸ©é˜µ) ---
        # æˆ‘ä»¬ç”¨è¿‡å»çš„æ•°æ®æ¥è®­ç»ƒæ¨¡å‹ã€‚
        # X: [t-order, ..., t-1], y: [t]
        
        def make_dataset(data):
            X, y = [], []
            for i in range(len(data) - self.order):
                X.append(data[i : i + self.order])
                y.append(data[i + self.order])
            return np.array(X), np.array(y)

        # å·¦ä¾§ä¸Šä¸‹æ–‡ (ç”¨äºæ­£å‘é¢„æµ‹)
        left_context = self.signal[:gap_start]
        X_left, y_left = make_dataset(left_context)
        
        # å³ä¾§ä¸Šä¸‹æ–‡ (ç”¨äºåå‘é¢„æµ‹) - éœ€è¦æŠŠæ•°ç»„ç¿»è½¬ï¼
        right_context = self.signal[gap_end:][::-1] # ç¿»è½¬
        X_right, y_right = make_dataset(right_context)
        
        # --- 2. åŒå‘é¢„æµ‹ ---
        print("ğŸ¤– æ­£åœ¨è¿›è¡ŒåŒå‘æ¨æ¼”...")
        # æ­£å‘é¢„æµ‹ (Forward)
        pred_fwd = self._train_predict(X_left, y_left, gap_len)
        
        # åå‘é¢„æµ‹ (Backward) - é¢„æµ‹å®Œè¦æŠŠç»“æœç¿»è½¬å›æ¥
        pred_bwd = self._train_predict(X_right, y_right, gap_len)
        pred_bwd = pred_bwd[::-1] 
        
        # --- 3. äº¤å‰æ·¡å…¥æ·¡å‡º (Cross-fading) ---
        # åœ¨ç¼ºå£å·¦è¾¹ä¿¡èµ–æ­£å‘ï¼Œå³è¾¹ä¿¡èµ–åå‘ï¼Œä¸­é—´å¹³æ»‘è¿‡æ¸¡
        weights = np.linspace(1, 0, gap_len) # æƒé‡ä» 1 å˜åˆ° 0
        restored_gap = pred_fwd * weights + pred_bwd * (1 - weights)
        
        restored_signal = self.signal.copy()
        restored_signal[gap_start:gap_end] = restored_gap
        
        return restored_signal, pred_fwd, pred_bwd
    
    def save_results(self, restored_signal):
        """Save audio files and spectrograms"""
        # Save corrupted audio
        corrupted_audio = self.signal.copy()
        gs, ge = self.gap_range
        corrupted_audio[gs:ge] = 0
        save_wav(corrupted_audio, self.sr, "ar_corrupted.wav")
        save_spectrogram(corrupted_audio, self.sr, "spec_ar_corrupted.png")
        
        # Save restored audio
        save_wav(restored_signal, self.sr, "ar_restored.wav")
        save_spectrogram(restored_signal, self.sr, "spec_ar_restored.png")
        
        # Save original
        save_wav(self.signal, self.sr, "ar_original.wav")
        save_spectrogram(self.signal, self.sr, "spec_ar_original.png")

    def visualize(self, final_sig, pred_fwd, pred_bwd):
        plt.figure(figsize=(12, 6))
        
        # åŸå§‹
        plt.plot(self.t, self.signal, 'gray', alpha=0.4, label='Ground Truth')
        
        # ç¼ºå£èƒŒæ™¯
        gs, ge = self.gap_range
        gap_t = self.t[gs:ge]
        plt.axvspan(self.t[gs], self.t[ge], color='red', alpha=0.1)
        
        # ç»˜åˆ¶æ­£å‘/åå‘çš„é¢„æµ‹è½¨è¿¹ï¼ˆè™šçº¿ï¼‰
        plt.plot(gap_t, pred_fwd, 'b--', alpha=0.5, linewidth=1, label='Forward Pred')
        plt.plot(gap_t, pred_bwd, 'g--', alpha=0.5, linewidth=1, label='Backward Pred')
        
        # æœ€ç»ˆèåˆç»“æœ
        plt.plot(gap_t, final_sig[gs:ge], 'r-', linewidth=2.5, label='Bidirectional AR (Final)')
        
        plt.title(f"Voice Inpainting: Bidirectional AR (Order={self.order})")
        plt.legend()
        plt.savefig(os.path.join(OUTPUT_DIR, "ar_waveform_viz.png"), dpi=300, bbox_inches='tight')
        print(f"ğŸ“Š Waveform visualization saved")
        plt.show()

# --- ğŸƒâ€â™‚ï¸ Run ---
if __name__ == "__main__":
    # Unified parameters
    DURATION = 0.05
    GAP_RATIO = 0.2
    
    lab = BidirectionalARInpainter(filename="vocals_accompaniment_10s.wav", duration=DURATION, order=30)
    lab.load_data()
    lab.apply_mask(gap_ratio=GAP_RATIO)
    final, fwd, bwd = lab.restore()
    lab.save_results(final)
    lab.visualize(final, fwd, bwd)
    
    print(f"âœ… Bidirectional AR restoration complete! Results in {OUTPUT_DIR}")