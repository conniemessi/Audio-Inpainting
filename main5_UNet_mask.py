import torch
import torch.nn as nn
import torch.optim as optim
import torchaudio
import numpy as np
import matplotlib.pyplot as plt
from scipy.io import wavfile
import os
from datetime import datetime

# --- 1. å®šä¹‰ U-Net ç½‘ç»œæ¶æ„ ---
class SimpleUNet(nn.Module):
    def __init__(self):
        super().__init__()
        # ç¼–ç å™¨ (Encoder): ä¸‹é‡‡æ ·ï¼Œæå–ç‰¹å¾
        self.enc1 = self.conv_block(1, 16)
        self.pool1 = nn.MaxPool2d(2)
        self.enc2 = self.conv_block(16, 32)
        self.pool2 = nn.MaxPool2d(2)
        self.bottleneck = self.conv_block(32, 64)

        # è§£ç å™¨ (Decoder): ä¸Šé‡‡æ ·ï¼Œæ¢å¤å›¾åƒ
        self.up2 = nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2)
        self.dec2 = self.conv_block(64, 32) # è¾“å…¥æ˜¯ 64 å› ä¸ºæ‹¼æ¥äº† skip connection
        self.up1 = nn.ConvTranspose2d(32, 16, kernel_size=2, stride=2)
        self.dec1 = self.conv_block(32, 16)
        
        # è¾“å‡ºå±‚
        self.final = nn.Conv2d(16, 1, kernel_size=1)

    def conv_block(self, in_ch, out_ch):
        return nn.Sequential(
            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1),
            nn.ReLU(inplace=True)
        )

    def forward(self, x):
        # ç¼–ç è·¯å¾„
        e1 = self.enc1(x)
        p1 = self.pool1(e1)
        e2 = self.enc2(p1)
        p2 = self.pool2(e2)
        
        # ç“¶é¢ˆå±‚
        b = self.bottleneck(p2)
        
        # è§£ç è·¯å¾„ (å¸¦è·³è·ƒè¿æ¥ Skip Connections)
        d2 = self.up2(b)
        # è°ƒæ•´å°ºå¯¸ä»¥é˜² padding å¯¼è‡´çš„ä¸åŒ¹é…
        d2 = torch.nn.functional.interpolate(d2, size=e2.shape[2:]) 
        d2 = torch.cat((e2, d2), dim=1) # æ‹¼æ¥!
        d2 = self.dec2(d2)
        
        d1 = self.up1(d2)
        d1 = torch.nn.functional.interpolate(d1, size=e1.shape[2:])
        d1 = torch.cat((e1, d1), dim=1) # æ‹¼æ¥!
        d1 = self.dec1(d1)
        
        return self.final(d1)

# --- 2. æ•°æ®å¤„ç†ä¸è®­ç»ƒæµç¨‹ ---
class DLInpaintingLab:
    def __init__(self, filename, duration=10.0): # 10ç§’é•¿éŸ³é¢‘
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ğŸš€ Using device: {self.device}")
        
        # åŠ è½½éŸ³é¢‘
        waveform, sr = torchaudio.load(filename)
        
        # 1. å¼ºåˆ¶è½¬å•å£°é“
        if waveform.shape[0] > 1:
            waveform = torch.mean(waveform, dim=0, keepdim=True)
            
        # ç¡®ä¿éŸ³é¢‘å¤Ÿé•¿ï¼Œä¸å¤Ÿé•¿å°±è¿™å°±å–å…¨éƒ¨
        target_len = int(duration * sr)
        if waveform.shape[1] > target_len:
            waveform = waveform[:, :target_len]
        else:
            print(f"âš ï¸ éŸ³é¢‘é•¿åº¦ä»…ä¸º {waveform.shape[1]/sr:.2f}s (å°äºè¯·æ±‚çš„ {duration}s)")
            
        self.sr = sr
        self.original_length = waveform.shape[1]
        
        # Window & STFT
        self.n_fft = 1024
        self.window = torch.hann_window(self.n_fft).to(self.device)
        
        waveform = waveform.to(self.device)
        stft = torch.stft(waveform, self.n_fft, hop_length=256, 
                          window=self.window, return_complex=True)
        
        self.magnitude = torch.abs(stft)
        self.phase = torch.angle(stft)
        
        # å½’ä¸€åŒ–
        self.mag_max = self.magnitude.max()
        self.magnitude_norm = self.magnitude / self.mag_max
        
        # --- ğŸ› ï¸ å‡çº§ç‚¹ï¼šéšæœºé®ç½©ç”Ÿæˆ (Smart Random Masking) ---
        self.mask = self._create_random_mask(self.magnitude_norm.shape)
        
        # Tensors
        self.input_mag = self.magnitude_norm * self.mask
        self.target_mag = self.magnitude_norm
        
        self.input_tensor = self.input_mag.unsqueeze(0)
        self.target_tensor = self.target_mag.unsqueeze(0)
        self.mask_tensor = self.mask.unsqueeze(0)

        self.model = SimpleUNet().to(self.device)
        self.restored_waveform = None
        self.corrupted_waveform = None
        
        # åˆ›å»ºå¸¦æ—¶é—´æˆ³çš„è¾“å‡ºæ–‡ä»¶å¤¹
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.output_dir = f"main6_results/output_{timestamp}"
        os.makedirs(self.output_dir, exist_ok=True)
        print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶å¤¹: {self.output_dir}")
        
        # é¢„å…ˆåˆ›å»ºæŸåçš„éŸ³é¢‘æ³¢å½¢ç”¨äºå¯¹æ¯”
        self._create_corrupted_waveform()

    def _create_random_mask(self, shape, mask_ratio=0.3, max_time_mask=30):
        """
        ç”Ÿæˆéšæœºçš„é®ç½©ï¼Œè€Œä¸æ˜¯å•ä¸€çš„å¤§ç¼ºå£ã€‚
        mask_ratio: é®ä½æ€»é¢ç§¯çš„ç™¾åˆ†æ¯”
        max_time_mask: æ¯ä¸ªå°ç¼ºå£æœ€å¤§çš„æ—¶é—´å®½åº¦ (å¸§æ•°)
        """
        _, freq, time = shape
        mask = torch.ones(shape).to(self.device)
        
        # ç®€å•çš„æ—¶é—´è½´éšæœºé®ç½© (Time Masking)
        # è¿™ç§æ–¹å¼ç±»ä¼¼ SpecAugment
        num_mask_segments = int(time * mask_ratio / max_time_mask * 2) # ä¼°ç®—éœ€è¦å¤šå°‘ä¸ªé®ç½©å—
        
        for _ in range(num_mask_segments):
            t_len = np.random.randint(5, max_time_mask) # éšæœºå®½åº¦ 5~30 å¸§
            t_start = np.random.randint(0, time - t_len)
            mask[:, :, t_start : t_start + t_len] = 0
            
        return mask

    # def _create_corrupted_waveform(self):
    #     """ä»æŸåçš„è¾“å…¥è°±å›¾é‡å»ºéŸ³é¢‘æ³¢å½¢"""
    #     # ä½¿ç”¨æŸåçš„å¹…åº¦è°±å’ŒåŸå§‹ç›¸ä½é‡å»º
    #     corrupted_mag = self.input_mag * self.mag_max
    #     stft_corrupted = torch.polar(corrupted_mag, self.phase)
        
    #     self.corrupted_waveform = torch.istft(
    #         stft_corrupted,
    #         self.n_fft,
    #         hop_length=256,
    #         window=self.window,
    #         length=self.original_length
    #     )
    
    def _create_corrupted_waveform(self):
        """ä»æŸåçš„è¾“å…¥è°±å›¾é‡å»ºéŸ³é¢‘æ³¢å½¢ï¼Œå¹¶ä¿å­˜ä¸ºåŸºå‡†æµ‹è¯•æ–‡ä»¶"""
        # ä½¿ç”¨æŸåçš„å¹…åº¦è°±å’ŒåŸå§‹ç›¸ä½é‡å»º
        corrupted_mag = self.input_mag * self.mag_max
        stft_corrupted = torch.polar(corrupted_mag, self.phase)
        
        self.corrupted_waveform = torch.istft(
            stft_corrupted,
            self.n_fft,
            hop_length=256,
            window=self.window,
            length=self.original_length
        )
        
        # --- âœ¨ æ–°å¢ï¼šä¿å­˜ä¸ºå…¬å…±åŸºå‡†æ–‡ä»¶ (è¦†ç›–æ—§çš„) ---
        os.makedirs("demo_assets", exist_ok=True)
        common_path = "demo_assets/damaged_random.wav"
        
        sig = self.corrupted_waveform.squeeze().cpu().numpy()
        sig = np.clip(sig, -1.0, 1.0)
        wavfile.write(common_path, self.sr, (sig * 32767).astype(np.int16))
        print(f"ğŸ‘‘ [åŸºå‡†ç”Ÿæˆ] U-Net å·²å°†å—æŸé¢˜ç›®å‘å¸ƒåˆ°: {common_path}")
        
        # åŒæ—¶ä¿å­˜ä¸€å¼ å¯¹åº”çš„ Mask å›¾ç‰‡ï¼Œæ–¹ä¾¿ Main4 NMF å‚è€ƒï¼ˆå¯é€‰ï¼Œä½†æ¨èï¼‰
        plt.figure(figsize=(10, 4))
        plt.specgram(sig, NFFT=1024, Fs=self.sr, noverlap=512, cmap='inferno')
        plt.axis('off')
        plt.tight_layout(pad=0)
        plt.savefig("demo_assets/spec_damaged_random.png", bbox_inches='tight', pad_inches=0)
        plt.close()

    def train_and_predict(self, epochs=600): # 10sæ•°æ®é‡å¤§ï¼Œepochå¯ä»¥é€‚å½“å‡å°‘ï¼Œæˆ–è€…ä¿æŒ
        optimizer = optim.Adam(self.model.parameters(), lr=0.001)
        criterion = nn.MSELoss()
        
        print(f"ğŸ§  å¼€å§‹è®­ç»ƒ U-Net (é•¿éŸ³é¢‘éšæœºé®ç½©ç‰ˆ, {epochs} è½®)...")
        for epoch in range(epochs):
            self.model.train()
            optimizer.zero_grad()
            output = self.model(self.input_tensor)
            
            # --- å…³é”®ï¼šLoss åªè®¡ç®—è¢«é®ä½çš„éƒ¨åˆ† (Hard Mining) ---
            # è¿™æ ·æ¨¡å‹ä¼šä¸“æ³¨äºä¿®å¤æœªçŸ¥åŒºåŸŸï¼Œè€Œä¸æ˜¯å¤è¯»å·²çŸ¥åŒºåŸŸ
            loss = criterion(output * (1-self.mask_tensor), self.target_tensor * (1-self.mask_tensor))
            # å¦‚æœè§‰å¾—å­¦å¾—å¤ªæ…¢ï¼Œå¯ä»¥ç”¨å…¨å±€ loss: loss = criterion(output, self.target_tensor)
            
            loss.backward()
            optimizer.step()
            
            if (epoch+1) % 100 == 0:
                print(f"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.6f}")
                
        # æ¨ç†
        self.model.eval()
        with torch.no_grad():
            predicted_mag_norm = self.model(self.input_tensor)
            
        final_mag_norm = self.input_mag.to(self.device) + predicted_mag_norm * (1 - self.mask_tensor)
        final_mag = final_mag_norm.squeeze(0) * self.mag_max
        
        stft_reconstructed = torch.polar(final_mag, self.phase)
        
        self.restored_waveform = torch.istft(
            stft_reconstructed, 
            self.n_fft, 
            hop_length=256, 
            window=self.window, 
            length=self.original_length 
        )

    def visualize(self):
        plt.figure(figsize=(15, 6)) # ç”»å¸ƒå¤§ä¸€ç‚¹
        
        plt.subplot(1, 3, 1)
        plt.title("Input (Randomly Masked)")
        plt.imshow(self.input_mag.squeeze().cpu().numpy(), aspect='auto', origin='lower', cmap='inferno')
        plt.axis('off')

        self.model.eval()
        with torch.no_grad():
            pred = self.model(self.input_tensor).squeeze(0).squeeze(0).cpu()
        
        plt.subplot(1, 3, 2)
        plt.title("U-Net Prediction")
        plt.imshow(pred.numpy(), aspect='auto', origin='lower', cmap='inferno')
        plt.axis('off')
        
        plt.subplot(1, 3, 3)
        plt.title("Ground Truth")
        plt.imshow(self.target_mag.squeeze().cpu().numpy(), aspect='auto', origin='lower', cmap='inferno')
        plt.axis('off')
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾ç‰‡ä¸º PNG å’Œ PDF
        png_path = os.path.join(self.output_dir, "spectrogram_comparison.png")
        pdf_path = os.path.join(self.output_dir, "spectrogram_comparison.pdf")
        plt.savefig(png_path, dpi=300, bbox_inches='tight')
        plt.savefig(pdf_path, bbox_inches='tight')
        print(f"ğŸ“Š å¯è§†åŒ–å›¾ç‰‡å·²ä¿å­˜: {png_path}")
        print(f"ğŸ“Š å¯è§†åŒ–å›¾ç‰‡å·²ä¿å­˜: {pdf_path}")
        
        plt.show()

    def save_wav(self):
        # ä¿å­˜æŸåçš„éŸ³é¢‘ï¼ˆä¿®å¤å‰ï¼‰
        if self.corrupted_waveform is not None:
            sig_corrupted = self.corrupted_waveform.squeeze().cpu().numpy()
            sig_corrupted = np.clip(sig_corrupted, -0.99, 0.99)
            corrupted_path = os.path.join(self.output_dir, "dl_long_corrupted.wav")
            wavfile.write(corrupted_path, self.sr, (sig_corrupted * 32767).astype(np.int16))
            print(f"ğŸ’¾ æŸåçš„éŸ³é¢‘å·²ä¿å­˜: {corrupted_path}")
        
        # ä¿å­˜ä¿®å¤åçš„éŸ³é¢‘
        sig = self.restored_waveform.squeeze().cpu().numpy()
        sig = np.clip(sig, -0.99, 0.99)
        restored_path = os.path.join(self.output_dir, "dl_long_restored.wav")
        wavfile.write(restored_path, self.sr, (sig * 32767).astype(np.int16))
        print(f"ğŸ’¾ é•¿éŸ³é¢‘ä¿®å¤å®Œæˆ: {restored_path}")
        
# --- ğŸƒâ€â™‚ï¸ è¿è¡Œ ---
# âš ï¸ æ³¨æ„ï¼šå¦‚æœä½ æ²¡æœ‰ GPUï¼Œè¿™å¯èƒ½éœ€è¦è·‘ä¸€ä¸¤åˆ†é’Ÿã€‚
lab = DLInpaintingLab(filename="vocals_accompaniment_10s.wav", duration=10)
lab.train_and_predict(epochs=400) # è®­ç»ƒ 600 è½®ç¡®ä¿è¿‡æ‹Ÿåˆ
lab.visualize()
lab.save_wav()